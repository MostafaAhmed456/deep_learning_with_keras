{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## keras and gensim for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text8Sentences(object):\n",
    "    def __init__(self,maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    def __iter__(self):\n",
    "        with open(\"text8\", \"rb\") as ftext:\n",
    "            print \"opened file\"\n",
    "            text = ftext.read().split(\" \")\n",
    "            words = []\n",
    "            for word in text:\n",
    "                if len(words) >= self.maxlen:\n",
    "                    yield words\n",
    "                    words = []\n",
    "                words.append(word)\n",
    "            yield words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = Text8Sentences(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:37:17,034 : INFO : collecting all words and their counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:37:18,019 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-05 14:37:18,376 : INFO : PROGRESS: at sentence #10000, processed 500000 words, keeping 33464 word types\n",
      "2018-09-05 14:37:18,725 : INFO : PROGRESS: at sentence #20000, processed 1000000 words, keeping 52755 word types\n",
      "2018-09-05 14:37:19,078 : INFO : PROGRESS: at sentence #30000, processed 1500000 words, keeping 65589 word types\n",
      "2018-09-05 14:37:19,464 : INFO : PROGRESS: at sentence #40000, processed 2000000 words, keeping 78383 word types\n",
      "2018-09-05 14:37:19,836 : INFO : PROGRESS: at sentence #50000, processed 2500000 words, keeping 88008 word types\n",
      "2018-09-05 14:37:20,174 : INFO : PROGRESS: at sentence #60000, processed 3000000 words, keeping 96645 word types\n",
      "2018-09-05 14:37:20,506 : INFO : PROGRESS: at sentence #70000, processed 3500000 words, keeping 104309 word types\n",
      "2018-09-05 14:37:20,896 : INFO : PROGRESS: at sentence #80000, processed 4000000 words, keeping 111461 word types\n",
      "2018-09-05 14:37:21,274 : INFO : PROGRESS: at sentence #90000, processed 4500000 words, keeping 118752 word types\n",
      "2018-09-05 14:37:21,635 : INFO : PROGRESS: at sentence #100000, processed 5000000 words, keeping 125355 word types\n",
      "2018-09-05 14:37:21,986 : INFO : PROGRESS: at sentence #110000, processed 5500000 words, keeping 133141 word types\n",
      "2018-09-05 14:37:22,408 : INFO : PROGRESS: at sentence #120000, processed 6000000 words, keeping 139566 word types\n",
      "2018-09-05 14:37:22,754 : INFO : PROGRESS: at sentence #130000, processed 6500000 words, keeping 145782 word types\n",
      "2018-09-05 14:37:23,114 : INFO : PROGRESS: at sentence #140000, processed 7000000 words, keeping 151934 word types\n",
      "2018-09-05 14:37:23,477 : INFO : PROGRESS: at sentence #150000, processed 7500000 words, keeping 158046 word types\n",
      "2018-09-05 14:37:23,825 : INFO : PROGRESS: at sentence #160000, processed 8000000 words, keeping 164115 word types\n",
      "2018-09-05 14:37:24,172 : INFO : PROGRESS: at sentence #170000, processed 8500000 words, keeping 171256 word types\n",
      "2018-09-05 14:37:24,538 : INFO : PROGRESS: at sentence #180000, processed 9000000 words, keeping 178163 word types\n",
      "2018-09-05 14:37:24,924 : INFO : PROGRESS: at sentence #190000, processed 9500000 words, keeping 184129 word types\n",
      "2018-09-05 14:37:25,257 : INFO : PROGRESS: at sentence #200000, processed 10000000 words, keeping 189075 word types\n",
      "2018-09-05 14:37:25,628 : INFO : PROGRESS: at sentence #210000, processed 10500000 words, keeping 194511 word types\n",
      "2018-09-05 14:37:25,963 : INFO : PROGRESS: at sentence #220000, processed 11000000 words, keeping 198758 word types\n",
      "2018-09-05 14:37:26,326 : INFO : PROGRESS: at sentence #230000, processed 11500000 words, keeping 203441 word types\n",
      "2018-09-05 14:37:26,695 : INFO : PROGRESS: at sentence #240000, processed 12000000 words, keeping 207895 word types\n",
      "2018-09-05 14:37:27,066 : INFO : PROGRESS: at sentence #250000, processed 12500000 words, keeping 212668 word types\n",
      "2018-09-05 14:37:27,423 : INFO : PROGRESS: at sentence #260000, processed 13000000 words, keeping 217128 word types\n",
      "2018-09-05 14:37:27,780 : INFO : PROGRESS: at sentence #270000, processed 13500000 words, keeping 221416 word types\n",
      "2018-09-05 14:37:28,147 : INFO : PROGRESS: at sentence #280000, processed 14000000 words, keeping 226855 word types\n",
      "2018-09-05 14:37:28,492 : INFO : PROGRESS: at sentence #290000, processed 14500000 words, keeping 231424 word types\n",
      "2018-09-05 14:37:28,859 : INFO : PROGRESS: at sentence #300000, processed 15000000 words, keeping 237391 word types\n",
      "2018-09-05 14:37:29,217 : INFO : PROGRESS: at sentence #310000, processed 15500000 words, keeping 241697 word types\n",
      "2018-09-05 14:37:29,547 : INFO : PROGRESS: at sentence #320000, processed 16000000 words, keeping 245649 word types\n",
      "2018-09-05 14:37:29,925 : INFO : PROGRESS: at sentence #330000, processed 16500000 words, keeping 249621 word types\n",
      "2018-09-05 14:37:30,265 : INFO : PROGRESS: at sentence #340000, processed 17000000 words, keeping 253834 word types\n",
      "2018-09-05 14:37:30,440 : INFO : collected 253855 word types from a corpus of 17005208 raw words and 340105 sentences\n",
      "2018-09-05 14:37:30,442 : INFO : Loading a fresh vocabulary\n",
      "2018-09-05 14:37:30,813 : INFO : min_count=30 retains 25097 unique words (9% of original 253855, drops 228758)\n",
      "2018-09-05 14:37:30,815 : INFO : min_count=30 leaves 16191060 word corpus (95% of original 17005208, drops 814148)\n",
      "2018-09-05 14:37:30,895 : INFO : deleting the raw counts dictionary of 253855 items\n",
      "2018-09-05 14:37:30,987 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2018-09-05 14:37:30,988 : INFO : downsampling leaves estimated 11928484 word corpus (73.7% of prior 16191060)\n",
      "2018-09-05 14:37:31,082 : INFO : estimated required memory for 25097 words and 300 dimensions: 72781300 bytes\n",
      "2018-09-05 14:37:31,083 : INFO : resetting layer weights\n",
      "2018-09-05 14:37:31,398 : INFO : training model with 3 workers on 25097 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:37:32,479 : INFO : EPOCH 1 - PROGRESS: at 0.06% examples, 6584 words/s, in_qsize 1, out_qsize 1\n",
      "2018-09-05 14:37:33,485 : INFO : EPOCH 1 - PROGRESS: at 5.12% examples, 292806 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:37:34,494 : INFO : EPOCH 1 - PROGRESS: at 9.64% examples, 368602 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:35,505 : INFO : EPOCH 1 - PROGRESS: at 15.05% examples, 434366 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:37:36,519 : INFO : EPOCH 1 - PROGRESS: at 20.41% examples, 472864 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:37,535 : INFO : EPOCH 1 - PROGRESS: at 25.58% examples, 496814 words/s, in_qsize 6, out_qsize 2\n",
      "2018-09-05 14:37:38,545 : INFO : EPOCH 1 - PROGRESS: at 30.93% examples, 516623 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:39,552 : INFO : EPOCH 1 - PROGRESS: at 36.17% examples, 530337 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:37:40,573 : INFO : EPOCH 1 - PROGRESS: at 41.75% examples, 544467 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:37:41,568 : INFO : EPOCH 1 - PROGRESS: at 46.99% examples, 552620 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:37:42,576 : INFO : EPOCH 1 - PROGRESS: at 52.28% examples, 559276 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:43,580 : INFO : EPOCH 1 - PROGRESS: at 57.63% examples, 566036 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-05 14:37:44,587 : INFO : EPOCH 1 - PROGRESS: at 62.69% examples, 568531 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:37:45,601 : INFO : EPOCH 1 - PROGRESS: at 68.04% examples, 572980 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:46,615 : INFO : EPOCH 1 - PROGRESS: at 73.80% examples, 580522 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:37:47,623 : INFO : EPOCH 1 - PROGRESS: at 79.27% examples, 583452 words/s, in_qsize 3, out_qsize 0\n",
      "2018-09-05 14:37:48,636 : INFO : EPOCH 1 - PROGRESS: at 84.68% examples, 586442 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:37:49,647 : INFO : EPOCH 1 - PROGRESS: at 89.74% examples, 587245 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:37:50,656 : INFO : EPOCH 1 - PROGRESS: at 95.15% examples, 589541 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:51,715 : INFO : EPOCH 1 - PROGRESS: at 99.56% examples, 584524 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:37:51,775 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 14:37:51,784 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 14:37:51,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 14:37:51,791 : INFO : EPOCH - 1 : training on 17005208 raw words (11928138 effective words) took 20.4s, 584998 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:37:52,828 : INFO : EPOCH 2 - PROGRESS: at 0.06% examples, 7241 words/s, in_qsize 0, out_qsize 0\n",
      "2018-09-05 14:37:53,835 : INFO : EPOCH 2 - PROGRESS: at 4.23% examples, 248827 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:54,852 : INFO : EPOCH 2 - PROGRESS: at 9.70% examples, 375924 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:37:55,857 : INFO : EPOCH 2 - PROGRESS: at 15.00% examples, 437891 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:37:56,849 : INFO : EPOCH 2 - PROGRESS: at 20.17% examples, 473257 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:37:57,870 : INFO : EPOCH 2 - PROGRESS: at 25.35% examples, 496263 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:37:58,877 : INFO : EPOCH 2 - PROGRESS: at 30.58% examples, 515428 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:37:59,892 : INFO : EPOCH 2 - PROGRESS: at 35.75% examples, 527874 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-05 14:38:00,897 : INFO : EPOCH 2 - PROGRESS: at 40.69% examples, 534157 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:01,916 : INFO : EPOCH 2 - PROGRESS: at 45.69% examples, 539879 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:38:02,918 : INFO : EPOCH 2 - PROGRESS: at 50.69% examples, 545129 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:38:03,943 : INFO : EPOCH 2 - PROGRESS: at 55.45% examples, 545894 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:04,956 : INFO : EPOCH 2 - PROGRESS: at 60.63% examples, 551223 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:05,950 : INFO : EPOCH 2 - PROGRESS: at 65.69% examples, 554916 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:06,963 : INFO : EPOCH 2 - PROGRESS: at 70.39% examples, 555313 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:38:07,965 : INFO : EPOCH 2 - PROGRESS: at 74.86% examples, 554059 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:38:08,974 : INFO : EPOCH 2 - PROGRESS: at 79.62% examples, 553446 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:09,976 : INFO : EPOCH 2 - PROGRESS: at 84.50% examples, 554839 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:10,981 : INFO : EPOCH 2 - PROGRESS: at 89.62% examples, 557555 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:11,985 : INFO : EPOCH 2 - PROGRESS: at 94.74% examples, 559847 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:38:13,139 : INFO : EPOCH 2 - PROGRESS: at 99.56% examples, 556346 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:13,187 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 14:38:13,189 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 14:38:13,193 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 14:38:13,194 : INFO : EPOCH - 2 : training on 17005208 raw words (11928627 effective words) took 21.4s, 557436 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:38:14,286 : INFO : EPOCH 3 - PROGRESS: at 0.18% examples, 19985 words/s, in_qsize 0, out_qsize 0\n",
      "2018-09-05 14:38:15,296 : INFO : EPOCH 3 - PROGRESS: at 5.23% examples, 297172 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:16,300 : INFO : EPOCH 3 - PROGRESS: at 10.41% examples, 396639 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:38:17,310 : INFO : EPOCH 3 - PROGRESS: at 14.64% examples, 421020 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:38:18,325 : INFO : EPOCH 3 - PROGRESS: at 19.58% examples, 453180 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:38:19,332 : INFO : EPOCH 3 - PROGRESS: at 24.40% examples, 473517 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:20,346 : INFO : EPOCH 3 - PROGRESS: at 29.34% examples, 489393 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:38:21,372 : INFO : EPOCH 3 - PROGRESS: at 34.28% examples, 501043 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:38:22,371 : INFO : EPOCH 3 - PROGRESS: at 39.28% examples, 511583 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:23,387 : INFO : EPOCH 3 - PROGRESS: at 44.46% examples, 521650 words/s, in_qsize 3, out_qsize 0\n",
      "2018-09-05 14:38:24,400 : INFO : EPOCH 3 - PROGRESS: at 48.46% examples, 517148 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:38:25,416 : INFO : EPOCH 3 - PROGRESS: at 53.57% examples, 524380 words/s, in_qsize 3, out_qsize 0\n",
      "2018-09-05 14:38:26,413 : INFO : EPOCH 3 - PROGRESS: at 58.86% examples, 532572 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:27,431 : INFO : EPOCH 3 - PROGRESS: at 64.10% examples, 538504 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:28,442 : INFO : EPOCH 3 - PROGRESS: at 68.92% examples, 540627 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:29,464 : INFO : EPOCH 3 - PROGRESS: at 73.92% examples, 543659 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:38:30,489 : INFO : EPOCH 3 - PROGRESS: at 79.45% examples, 548493 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:31,505 : INFO : EPOCH 3 - PROGRESS: at 84.74% examples, 552453 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:32,534 : INFO : EPOCH 3 - PROGRESS: at 89.50% examples, 552375 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:33,547 : INFO : EPOCH 3 - PROGRESS: at 94.44% examples, 553670 words/s, in_qsize 3, out_qsize 0\n",
      "2018-09-05 14:38:34,565 : INFO : EPOCH 3 - PROGRESS: at 99.15% examples, 553363 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:38:34,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 14:38:34,931 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 14:38:34,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 14:38:34,938 : INFO : EPOCH - 3 : training on 17005208 raw words (11928046 effective words) took 21.7s, 548637 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:38:36,097 : INFO : EPOCH 4 - PROGRESS: at 0.06% examples, 6495 words/s, in_qsize 0, out_qsize 0\n",
      "2018-09-05 14:38:37,102 : INFO : EPOCH 4 - PROGRESS: at 4.94% examples, 272914 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:38,105 : INFO : EPOCH 4 - PROGRESS: at 10.11% examples, 377912 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:39,106 : INFO : EPOCH 4 - PROGRESS: at 15.23% examples, 432666 words/s, in_qsize 3, out_qsize 0\n",
      "2018-09-05 14:38:40,124 : INFO : EPOCH 4 - PROGRESS: at 20.46% examples, 468667 words/s, in_qsize 1, out_qsize 1\n",
      "2018-09-05 14:38:41,139 : INFO : EPOCH 4 - PROGRESS: at 25.11% examples, 482686 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:42,133 : INFO : EPOCH 4 - PROGRESS: at 30.28% examples, 502281 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:38:43,147 : INFO : EPOCH 4 - PROGRESS: at 35.40% examples, 515461 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:44,153 : INFO : EPOCH 4 - PROGRESS: at 40.63% examples, 527030 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:45,165 : INFO : EPOCH 4 - PROGRESS: at 45.81% examples, 535755 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:46,192 : INFO : EPOCH 4 - PROGRESS: at 50.93% examples, 542496 words/s, in_qsize 6, out_qsize 3\n",
      "2018-09-05 14:38:47,183 : INFO : EPOCH 4 - PROGRESS: at 56.28% examples, 550167 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:38:48,185 : INFO : EPOCH 4 - PROGRESS: at 61.63% examples, 556699 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:38:49,188 : INFO : EPOCH 4 - PROGRESS: at 66.80% examples, 560765 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:50,196 : INFO : EPOCH 4 - PROGRESS: at 71.98% examples, 564437 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:38:51,203 : INFO : EPOCH 4 - PROGRESS: at 77.27% examples, 567460 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:38:52,216 : INFO : EPOCH 4 - PROGRESS: at 82.50% examples, 569999 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:53,223 : INFO : EPOCH 4 - PROGRESS: at 87.80% examples, 573225 words/s, in_qsize 2, out_qsize 0\n",
      "2018-09-05 14:38:54,235 : INFO : EPOCH 4 - PROGRESS: at 92.91% examples, 574887 words/s, in_qsize 4, out_qsize 2\n",
      "2018-09-05 14:38:55,234 : INFO : EPOCH 4 - PROGRESS: at 98.32% examples, 577965 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:38:55,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 14:38:55,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 14:38:55,743 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 14:38:55,744 : INFO : EPOCH - 4 : training on 17005208 raw words (11927892 effective words) took 20.8s, 573433 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opened file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:38:56,811 : INFO : EPOCH 5 - PROGRESS: at 0.06% examples, 7117 words/s, in_qsize 1, out_qsize 0\n",
      "2018-09-05 14:38:57,814 : INFO : EPOCH 5 - PROGRESS: at 5.06% examples, 292056 words/s, in_qsize 6, out_qsize 1\n",
      "2018-09-05 14:38:58,824 : INFO : EPOCH 5 - PROGRESS: at 10.29% examples, 395515 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:38:59,836 : INFO : EPOCH 5 - PROGRESS: at 14.58% examples, 422227 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:39:00,845 : INFO : EPOCH 5 - PROGRESS: at 19.35% examples, 450430 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:39:01,848 : INFO : EPOCH 5 - PROGRESS: at 24.35% examples, 475034 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:39:02,854 : INFO : EPOCH 5 - PROGRESS: at 28.87% examples, 484380 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:39:03,865 : INFO : EPOCH 5 - PROGRESS: at 33.52% examples, 493035 words/s, in_qsize 4, out_qsize 1\n",
      "2018-09-05 14:39:04,882 : INFO : EPOCH 5 - PROGRESS: at 38.40% examples, 503130 words/s, in_qsize 5, out_qsize 2\n",
      "2018-09-05 14:39:05,874 : INFO : EPOCH 5 - PROGRESS: at 43.52% examples, 513823 words/s, in_qsize 2, out_qsize 1\n",
      "2018-09-05 14:39:06,880 : INFO : EPOCH 5 - PROGRESS: at 48.81% examples, 524182 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:39:07,892 : INFO : EPOCH 5 - PROGRESS: at 53.87% examples, 530311 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:39:08,903 : INFO : EPOCH 5 - PROGRESS: at 59.04% examples, 536811 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:39:09,910 : INFO : EPOCH 5 - PROGRESS: at 64.27% examples, 542778 words/s, in_qsize 5, out_qsize 0\n",
      "2018-09-05 14:39:10,912 : INFO : EPOCH 5 - PROGRESS: at 69.45% examples, 547747 words/s, in_qsize 6, out_qsize 0\n",
      "2018-09-05 14:39:11,933 : INFO : EPOCH 5 - PROGRESS: at 74.98% examples, 554248 words/s, in_qsize 3, out_qsize 0\n",
      "2018-09-05 14:39:12,937 : INFO : EPOCH 5 - PROGRESS: at 80.03% examples, 555992 words/s, in_qsize 3, out_qsize 1\n",
      "2018-09-05 14:39:13,939 : INFO : EPOCH 5 - PROGRESS: at 85.27% examples, 559661 words/s, in_qsize 4, out_qsize 0\n",
      "2018-09-05 14:39:14,949 : INFO : EPOCH 5 - PROGRESS: at 90.50% examples, 562776 words/s, in_qsize 5, out_qsize 1\n",
      "2018-09-05 14:39:15,955 : INFO : EPOCH 5 - PROGRESS: at 96.03% examples, 567126 words/s, in_qsize 3, out_qsize 0\n",
      "2018-09-05 14:39:16,902 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 14:39:16,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 14:39:16,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 14:39:16,909 : INFO : EPOCH - 5 : training on 17005208 raw words (11929246 effective words) took 21.2s, 563717 effective words/s\n",
      "2018-09-05 14:39:16,910 : INFO : training on a 85026040 raw words (59641949 effective words) took 105.5s, 565270 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, size=300, min_count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:39:26,415 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 14:39:28,448 : INFO : saving Word2Vec object under word2vec_gensim.bin, separately None\n",
      "2018-09-05 14:39:28,451 : INFO : not storing attribute vectors_norm\n",
      "2018-09-05 14:39:28,453 : INFO : not storing attribute cum_table\n",
      "2018-09-05 14:39:28,760 : INFO : saved word2vec_gensim.bin\n"
     ]
    }
   ],
   "source": [
    "model.save(\"word2vec_gensim.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('film', 0.8082249760627747),\n",
       " ('movies', 0.7495356202125549),\n",
       " ('films', 0.7133634090423584),\n",
       " ('batman', 0.6987512707710266),\n",
       " ('cartoon', 0.6879000067710876),\n",
       " ('animated', 0.670574426651001),\n",
       " ('remake', 0.6572884321212769),\n",
       " ('sitcom', 0.6481475830078125),\n",
       " ('storyline', 0.6478568315505981),\n",
       " ('parody', 0.6405602693557739)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6281276941299438),\n",
       " ('throne', 0.5623317360877991),\n",
       " ('empress', 0.5621578693389893),\n",
       " ('prince', 0.557801365852356),\n",
       " ('daughter', 0.5378096103668213),\n",
       " ('isabella', 0.536970853805542),\n",
       " ('elizabeth', 0.5270385146141052),\n",
       " ('consort', 0.5268187522888184),\n",
       " ('sigismund', 0.5190441608428955),\n",
       " ('princess', 0.5183331966400146)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'],\n",
    "                   negative=['man'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
