{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers.core import Dense , Dropout , Activation , Flatten\n",
    "from keras.layers.convolutional import Conv2D , MaxPooling2D \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR_MODEL(rows,cols,channels , classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3) , padding='same',input_shape=(rows,cols,channels)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "    model.add(Dropout(.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    \n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train , Y_train),(X_test , Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (50000, 32, 32, 3)\n",
      "X_train (50000, 1)\n",
      "X_train (10000, 32, 32, 3)\n",
      "X_train (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print \"X_train\",X_train.shape\n",
    "print \"X_train\",Y_train.shape\n",
    "print \"X_train\",X_test.shape\n",
    "print \"X_train\",Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /=255\n",
    "X_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train,10)\n",
    "Y_test  = np_utils.to_categorical(Y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model   = CIFAR_MODEL(32,32,3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.0306 - acc: 0.6366\n",
      "Epoch 2/4\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9832 - acc: 0.6503\n",
      "Epoch 3/4\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9408 - acc: 0.6691\n",
      "Epoch 4/4\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.9037 - acc: 0.6809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2572ab10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , Y_train , epochs=4 , batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 344us/step\n",
      "test loss 0.9518934785842895\n",
      "test accuracy 0.6647\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,Y_test)\n",
    "print \"test loss\",score[0]\n",
    "print  \"test accuracy\",score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Bad results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# improve CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to improve the performance is to define a deeper network with multiple convolutional operations\n",
    "\n",
    "###### conv+conv+maxpool+dropout+conv+conv+maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CIFAR_MODEL(rows,cols,channels , classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3) , padding='same',input_shape=(rows,cols,channels)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters= 32 , kernel_size=3 , padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
    "    model.add(Dropout(.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64,kernel_size = 3 ,padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters = 64,kernel_size = 3 ,padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Dropout(.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model   = CIFAR_MODEL(32,32,3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train , Y_train , epochs=20 , batch_size=128,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "test loss 0.6957298518657684\n",
      "test accuracy 0.7941\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,Y_test)\n",
    "print \"test loss\",score[0]\n",
    "print  \"test accuracy\",score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the CIFAR-10 performance with data augmentation\n",
    "improve the performance is to generate more images for our training. The key intuition is that we can take the standard CIFAR training set and augment this set with multiple types of transformations including rotation, rescaling, horizontal/vertical flip, zooming, channel shift, and many more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=128,\n",
    "                    epochs=40, validation_split=.2,verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
